{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRRblk1QY6gR"
      },
      "source": [
        "# Easy Visa (Visa Application Analysis and Classification)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This project focuses on analyzing and predicting visa application outcomes using machine learning. The Office of Foreign Labor Certification (OFLC) processes thousands of applications for employers seeking to bring foreign workers into the U.S. every year. As the number of applications increases, it becomes increasingly tedious to manually review all cases.\n",
        "\n",
        "This project aims to:\n",
        "- Facilitate the process of visa approvals using a machine learning classification model.\n",
        "- Recommend a suitable profile for applicants based on the significant factors that influence visa approval or denial.\n",
        "\n",
        "## Objective\n",
        "\n",
        "In FY 2016, the OFLC processed 775,979 employer applications for 1,699,957 positions, a 9% increase from the previous year. Given this increasing number of applications, the goal of this project is to develop a **Machine Learning** solution that helps predict visa certification outcomes and shortlists candidates with a higher likelihood of approval.\n",
        "\n",
        "## Dataset Description\n",
        "\n",
        "The dataset contains attributes related to both the employee (foreign worker) and the employer. Below are key columns in the data:\n",
        "\n",
        "- **case_id**: ID of each visa application.\n",
        "- **continent**: Continent of the employee.\n",
        "- **education_of_employee**: Employee's education level.\n",
        "- **has_job_experience**: Indicates if the employee has previous job experience (Y/N).\n",
        "- **requires_job_training**: Indicates if job training is required (Y/N).\n",
        "- **no_of_employees**: Number of employees in the employer's company.\n",
        "- **yr_of_estab**: Year the employer's company was established.\n",
        "- **region_of_employment**: U.S. region where the foreign worker is employed.\n",
        "- **prevailing_wage**: Average wage paid to similarly employed workers in the occupation area.\n",
        "- **unit_of_wage**: Wage unit (Hourly, Weekly, Monthly, Yearly).\n",
        "- **full_time_position**: Whether the position is full-time (Y/N).\n",
        "- **case_status**: Visa certification status (Certified/Denied).\n",
        "\n",
        "## Exploratory Data Analysis (EDA) Questions\n",
        "\n",
        "The EDA seeks to answer key questions that will help us understand the drivers of visa certification:\n",
        "\n",
        "1. **Education and Certification**: Does education level impact visa certification?\n",
        "2. **Continent and Visa Status**: How does visa certification vary across different continents?\n",
        "3. **Work Experience**: Does having job experience influence visa approval?\n",
        "4. **Wage Unit**: Which wage unit (Hourly, Weekly, Monthly, Yearly) is most likely to lead to visa certification?\n",
        "5. **Prevailing Wage**: How does visa status change with different levels of prevailing wage?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install XgBoost,catboost,lightbgm\n",
        "!pip install xgboost\n",
        "!pip install catboost\n",
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo8FkrKQgsYs",
        "outputId": "0cab9065-c927-4110-8c3e-de40669f143b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlnvzQPLY6gT"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Library to help with statistical analysis\n",
        "import scipy.stats as stats\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from matplotlib.colors import ListedColormap\n",
        "# To get diferent metric scores\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import statsmodels.api as sm\n",
        "# To build model for prediction\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Import standard scalar\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import timeit\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# To ignore unnecessary warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "n3qHxz3_Y6gU"
      },
      "outputs": [],
      "source": [
        "# mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/Python Course'"
      ],
      "metadata": {
        "id": "ZhAEkGBOepw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store pellete for future use\n",
        "pellete='Set2'\n",
        "colors = sns.color_palette(pellete)  # Get Set2 color palette for future use\n",
        "sns.set(style=\"darkgrid\") # Set grid style"
      ],
      "metadata": {
        "id": "-bq72SzEksDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Overview**"
      ],
      "metadata": {
        "id": "7kp73zODuZ0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Observe the first few rows of the dataset, to check whether the dataset has been loaded properly or not\n",
        "- Get information about the number of rows and columns in the dataset\n",
        "- Find out the data types of the columns to ensure that data is stored in the preferred format and the value of each property is as expected.\n",
        "- Check the statistical summary of the dataset to get an overview of the numerical columns of the data\n",
        "- Check for missing values\n",
        "- Check for null values"
      ],
      "metadata": {
        "id": "1qOhFSCcuV2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data in to panda dataframe\n",
        "ez_df=pd.read_csv(f'{path}/EasyVisa.csv')"
      ],
      "metadata": {
        "id": "9jQQI-3TZvXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep copy the dataframe\n",
        "ezdf=ez_df.copy(deep=True)"
      ],
      "metadata": {
        "id": "d6xZZpdcercB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detail info about the dataset\n",
        "ezdf.info()"
      ],
      "metadata": {
        "id": "5iQ5fpn_hK_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "The dataset contains 12 columns.  \n",
        "Below is the summary:\n",
        "\n",
        "#### Dataset Summary\n",
        "\n",
        "| Column                               | Data Type | Non-Null Count | Description                               |\n",
        "|--------------------------------------|-----------|----------------|-------------------------------------------|\n",
        "| `case_id`                           | Object    | 25480          | Unique identifier for each case          |\n",
        "| `continent`                         | Object    | 25480          | Continent of the employment region        |\n",
        "| `education_of_employee`             | Object    | 25480          | Education level of the employee           |\n",
        "| `has_job_experience`                | Object    | 25480          | Indicates if the employee has experience  |\n",
        "| `requires_job_training`             | Object    | 25480          | Indicates if training is required         |\n",
        "| `no_of_employees`                   | Int64     | 25480          | Number of employees in the organization   |\n",
        "| `yr_of_estab`                       | Int64     | 25480          | Year of establishment                      |\n",
        "| `region_of_employment`              | Object    | 25480          | Region of employment                       |\n",
        "| `prevailing_wage`                   | Float64   | 25480          | Wage prevailing in the region             |\n",
        "| `unit_of_wage`                      | Object    | 25480          | Unit of wage (hourly, yearly, etc.)      |\n",
        "| `full_time_position`                | Object    | 25480          | Indicates if the position is full-time    |\n",
        "| `case_status`                       | Object    | 25480          | Status of the case (approved, denied, etc.) |\n"
      ],
      "metadata": {
        "id": "3tQ7hBwqwLTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check null values\n",
        "ezdf.isnull().sum()"
      ],
      "metadata": {
        "id": "V7AJcuTQvd05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf.shape"
      ],
      "metadata": {
        "id": "QeuZYQMYlKmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "There are 25480 rows and 12 colums in the dataset. The dataframe has no null value. Row 5 , 6 and 8 has numeric values."
      ],
      "metadata": {
        "id": "UnnJKWRvxvx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf.head(5)"
      ],
      "metadata": {
        "id": "1H5iUW5fhRx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "\n",
        "#### Categorical Columns\n",
        "- `case_id` (Object)\n",
        "- `continent` (Object)\n",
        "- `education_of_employee` (Object)\n",
        "- `has_job_experience` (Object)\n",
        "- `requires_job_training` (Object)\n",
        "- `region_of_employment` (Object)\n",
        "- `unit_of_wage` (Object)\n",
        "- `full_time_position` (Object)\n",
        "- `case_status` (Object)\n",
        "\n",
        "#### Numerical Columns\n",
        "- `no_of_employees` (Int64)\n",
        "- `yr_of_estab` (Int64)\n",
        "- `prevailing_wage` (Float64)\n",
        "\n",
        "### Summary\n",
        "- **Total Categorical Columns:** 9\n",
        "- **Total Numerical Columns:** 3"
      ],
      "metadata": {
        "id": "uI5krN9Nwq1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates in dataset\n",
        "has_duplicates = ezdf.duplicated().any()\n",
        "\n",
        "print(f\"Does the DataFrame have duplicates? {has_duplicates}\")"
      ],
      "metadata": {
        "id": "_zNr5Do4j6DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique values\n",
        "# Take all catgorical columns apart from case_id as this column seems to be unique column for joining or ref\n",
        "catgoricalcol=ezdf.select_dtypes(include=['object']).columns[1:]\n",
        "for col in catgoricalcol:\n",
        "  print(f'Unique values in {col}:')\n",
        "  print(ezdf[col].unique())"
      ],
      "metadata": {
        "id": "3gSx3X3eyUvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "#### Unique Values for Categorical Columns\n",
        "\n",
        "- **Continent:**\n",
        "  - `['Asia', 'Africa', 'North America', 'Europe', 'South America', 'Oceania']`\n",
        "  \n",
        "- **Education of Employee:**\n",
        "  - `['High School', \"Master's\", \"Bachelor's\", 'Doctorate']`\n",
        "  \n",
        "- **Has Job Experience:**\n",
        "  - `['N', 'Y']`\n",
        "  \n",
        "- **Requires Job Training:**\n",
        "  - `['N', 'Y']`\n",
        "  \n",
        "- **Region of Employment:**\n",
        "  - `['West', 'Northeast', 'South', 'Midwest', 'Island']`\n",
        "  \n",
        "- **Unit of Wage:**\n",
        "  - `['Hour', 'Year', 'Week', 'Month']`\n",
        "  \n",
        "- **Full-Time Position:**\n",
        "  - `['Y', 'N']`\n",
        "  \n",
        "- **Case Status:**\n",
        "  - `['Denied', 'Certified']`\n"
      ],
      "metadata": {
        "id": "i9PZIHT44_9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing no of values in each of these catgorical variable\n",
        "for col in catgoricalcol:\n",
        "  print(f'No of values in each {col}:')\n",
        "  print(ezdf[col].value_counts(normalize=True)*100)"
      ],
      "metadata": {
        "id": "1H1UnbAdqRoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Highest number of visa applications are from Asia (66%)\n",
        "- Most of the people who applied for visa have bachelors degree(40%)\n",
        "- Most of the pople has experienced  in the job which they are apply for in abroad.(58%)\n",
        "- Most of the people who applied for visa doesnot need any trainings(88%).We can assume that as people are experienced so they might not be needing trainings\n",
        "- Northeast region employment has highest no of visa though other regions are not far behind(28%)\n",
        "- Around 90% of peoplew who applied for visa are applying job on yearly wage rate\n",
        "- Most of the people who applied for visa are for full time employment(89%)\n",
        "- The approval  rate of visa is much higher the rejection (66%)\n"
      ],
      "metadata": {
        "id": "_NwM4Hikrbky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf.describe(exclude='object').T"
      ],
      "metadata": {
        "id": "UcYGst6l32jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- The min value for no_of_employees is -26 (This seems to be an problem as nagative of employees does not make sense it)\n",
        "- There is huge gap between 75% in no of employees i.e 3504 where as max value is 602069 .This might be due to large orginzation who has more man power.\n",
        "- Average prevailing wage is $74455.There's also a very huge difference in 75th percentile and maximum value.SO there might be some outliers.\n",
        "- The oldest company who has applied for visa for its employee is established in 1800\n",
        "\n"
      ],
      "metadata": {
        "id": "Wr3MObX76L1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter all values with nagative number of employees\n",
        "ezdf[ezdf['no_of_employees']<0]"
      ],
      "metadata": {
        "id": "Q-hybMrZos9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "We cannot drop these rows directly as only one field **no_of_employees** have this issue where as other fields might ve playing significant role if visa is certified or denied .We will make those nagative values as positive assuming that someone might have put nagative as hyphen by mistake"
      ],
      "metadata": {
        "id": "gObhvyabpF6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf.describe(include='object').T"
      ],
      "metadata": {
        "id": "vhioLlIm7Sj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights from Categorical Columns\n",
        "1. **Continent:**\n",
        "   - **Unique Values:** 6 (Asia, Africa, North America, Europe, South America, Oceania)\n",
        "   - **Most Frequent Value:** Asia (16,861 occurrences)\n",
        "   - **Insight:** A significant proportion of cases are concentrated in Asia, suggesting a possible focus area for analysis or resource allocation.\n",
        "\n",
        "2. **Education of Employee:**\n",
        "   - **Unique Values:** 4 (High School, Bachelor's, Master's, Doctorate)\n",
        "   - **Most Frequent Value:** Bachelor's degree (10,234 occurrences)\n",
        "   - **Insight:** The majority of employees have a Bachelor's degree, which may imply a workforce that is moderately educated, with potential implications for job requirements and training needs.\n",
        "\n",
        "3. **Job Experience:**\n",
        "   - **Unique Values:** 2 (Yes, No)\n",
        "   - **Most Frequent Value:** Yes (14,802 occurrences)\n",
        "   - **Insight:** A substantial number of employees possess job experience, indicating a more skilled workforce that could reduce training time and costs.\n",
        "\n",
        "4. **Job Training Requirement:**\n",
        "   - **Unique Values:** 2 (Yes, No)\n",
        "   - **Most Frequent Value:** No (22,525 occurrences)\n",
        "   - **Insight:** A majority of cases do not require job training, suggesting that the workforce may already be well-trained or that job roles typically do not demand extensive training.\n",
        "\n",
        "5. **Region of Employment:**\n",
        "   - **Unique Values:** 5 (West, Northeast, South, Midwest, Island)\n",
        "   - **Most Frequent Value:** Northeast (7,195 occurrences)\n",
        "   - **Insight:** The Northeast region has the highest representation.\n",
        "6. **Unit of Wage:**\n",
        "   - **Unique Values:** 4 (Hour, Year, Week, Month)\n",
        "   - **Most Frequent Value:** Year (22,962 occurrences)\n",
        "   - **Insight:** Most employees are compensated on an annual basis, which is typical for salaried positions, indicating a potential need to analyze wage structures and salary ranges.\n",
        "\n",
        "7. **Full-Time Position:**\n",
        "   - **Unique Values:** 2 (Yes, No)\n",
        "   - **Most Frequent Value:** Yes (22,773 occurrences)\n",
        "   - **Insight:** The majority of cases are full-time positions, which could reflect workforce stability and employee retention strategies.\n",
        "\n",
        "8. **Case Status:**\n",
        "   - **Unique Values:** 2 (Certified, Denied)\n",
        "   - **Most Frequent Value:** Certified (17,018 occurrences)\n",
        "   - **Insight:** A large number of cases are certified, which may indicate effective application processes or favorable conditions for approval."
      ],
      "metadata": {
        "id": "f7rNdT_o7eEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting all object columns to category type for better processing\n",
        "column=ezdf.columns[ezdf.dtypes=='object'][1:]\n",
        "for col in column:\n",
        "  ezdf[col]=ezdf[col].astype('category')"
      ],
      "metadata": {
        "id": "QFBTD9mu8sZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the scehma\n",
        "ezdf.info()"
      ],
      "metadata": {
        "id": "RCJE8Bty-iaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "ZCU6yHp7_ADY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bar_chart_percentage(df, column_name, xlabel, pellete, bar_width=0.6):\n",
        "    \"\"\"\n",
        "    Plots the percentage distribution of a specified categorical column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame containing the data.\n",
        "    - column_name: The name of the column to analyze.\n",
        "    - colors: List of colors for the bar plot.\n",
        "    - figsize: Tuple specifying the figure size.\n",
        "    - bar_width: Width of the bars in the bar plot.\n",
        "    \"\"\"\n",
        "    # Calculate the percentage of each category in the specified column\n",
        "    percentages = df[column_name].value_counts(normalize=True)*100\n",
        "    percentages = percentages.reset_index().rename(columns={ column_name: column_name, 'proportion': 'percent'})\n",
        "    n=df[column_name].nunique()\n",
        "    # Increase figure size for better readability\n",
        "    plt.figure(figsize=(n+1,6))\n",
        "\n",
        "    # Plot the bar plot with reduced bar width\n",
        "    ax=sns.barplot(x=column_name, y='percent', data=percentages, palette=pellete,hue=column_name, width=bar_width)\n",
        "\n",
        "    # Annotate the plot with the count values\n",
        "    annotate_chart(plt, ax)\n",
        "\n",
        "    # Set labels and title\n",
        "    plt.ylabel('Percentage')\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.title(f'Overview of {xlabel}')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlapping\n",
        "    plt.legend([],[], frameon=False)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Kuca_i35dlIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pie_chart_with_legend(df, column, title=None, colors=None):\n",
        "    \"\"\"\n",
        "    Creates a pie chart with a legend showing the share of each category in a column.\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): The DataFrame containing the data.\n",
        "    - column (str): The column name for which the pie chart will be created.\n",
        "    - title (str, optional): Title of the pie chart. Default is \"Market Segment Proportions\".\n",
        "    - colors (list, optional): List of colors for the pie chart wedges. If not provided, default pastel colors will be used.\n",
        "\n",
        "    Returns:\n",
        "    - plt (matplotlib.pyplot): The matplotlib plot object.\n",
        "    \"\"\"\n",
        "    # Calculate proportions\n",
        "    proportions = df[column].value_counts(normalize=True)\n",
        "\n",
        "    # Create the pie chart without annotations\n",
        "    plt.pie(proportions, labels=None, colors=colors, wedgeprops={'edgecolor': 'white'})\n",
        "\n",
        "    # Generate legend labels with percentages\n",
        "    legend_labels = [f'{label}: {percent:.1%}' for label, percent in zip(proportions.index, proportions)]\n",
        "\n",
        "    # Add the legend\n",
        "    plt.legend(legend_labels, loc='best', title=column.replace('_', ' ').title())\n",
        "\n",
        "    # Add title and adjust layout\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Return the plot\n",
        "    return plt"
      ],
      "metadata": {
        "id": "ThS2ss6wqUoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_histogram_and_boxplot(df, column, xlabel, ylabel, title):\n",
        "    \"\"\"\n",
        "    Plots a histogram with KDE and a box plot for a specified column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): The DataFrame containing the data.\n",
        "    column (str): The column name for which the plots are to be drawn.\n",
        "    xlabel (str): The label for the x-axis.\n",
        "    ylabel (str): The label for the y-axis.\n",
        "    title (str): The title for the graph.\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Calculate percentiles\n",
        "    q25 = df[column].quantile(0.25)\n",
        "    q50 = df[column].quantile(0.50)\n",
        "    q75 = df[column].quantile(0.75)\n",
        "    mean_value = df[column].mean()\n",
        "    # Create the figure and set the size\n",
        "    f, (hist, box) = plt.subplots(nrows=2, sharex=True, figsize=(8, 10))\n",
        "\n",
        "    # Create the histogram with KDE\n",
        "    sns.histplot(data=df, x=column, ax=hist, kde=True, legend=True, color='lightcoral')\n",
        "    hist.set_xlabel(xlabel)\n",
        "    hist.axvline(mean_value, color='peru', linestyle=':', label='Mean')\n",
        "    hist.axvline(q25, color='green', linestyle='--', label='25th percentile')\n",
        "    hist.axvline(q50, color='blue', linestyle='-', label='50th percentile (Median)')\n",
        "    hist.axvline(q75, color='purple', linestyle='--', label='75th percentile')\n",
        "    hist.set_ylabel(ylabel)\n",
        "    hist.legend()\n",
        "\n",
        "    # Create the box plot in a subplot below the histogram\n",
        "    sns.boxplot(data=df, x=column, ax=box, color='lightcoral')\n",
        "    box.axvline(mean_value, color='peru', linestyle=':', label=f'Mean: {mean_value:.2f}')\n",
        "    box.axvline(q25, color='green', linestyle='--', label=f'25th percentile: {q25:.2f}')\n",
        "    box.axvline(q50, color='blue', linestyle='-', label=f'50th percentile: {q50:.2f}')\n",
        "    box.axvline(q75, color='purple', linestyle='--', label=f'75th percentile: {q75:.2f}')\n",
        "\n",
        "    # Setting the x-label and title on the shared axis and figure\n",
        "    box.set_xlabel(xlabel)\n",
        "    f.suptitle(title)\n",
        "\n",
        "    # Adjust layout and show the combined plots\n",
        "    f.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    box.legend()  # Add legend to the box plot for the percentiles\n"
      ],
      "metadata": {
        "id": "is5yeZJfVksV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_count_plot(df, x, xlabel, ylabel, title, hue=None):\n",
        "    \"\"\"\n",
        "    Draws a count plot for a specified column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): The DataFrame containing the data.\n",
        "    - x (str): The column name to be used for the x-axis categories.\n",
        "    - xlabel (str): The label for the x-axis.\n",
        "    - ylabel (str): The label for the y-axis.\n",
        "    - title (str): The title for the plot.\n",
        "    - hue (str, optional): The column name to be used for hue (categorical separation). Default is None.\n",
        "\n",
        "    Returns:\n",
        "    - plt (matplotlib.pyplot): The matplotlib plot object.\n",
        "    \"\"\"\n",
        "    # Create the plot\n",
        "    count=df[x].nunique()\n",
        "    plt.figure(figsize=(count + 1, 4))\n",
        "    ax = sns.countplot(data=df, x=x, hue=hue, palette='Set2')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "\n",
        "    # Annotate the plot with the count values\n",
        "    annotate_chart(plt, ax)\n",
        "\n",
        "    return plt"
      ],
      "metadata": {
        "id": "iC-GVQtTA25-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def annotate_chart(plot, ax):\n",
        "    \"\"\"\n",
        "    Annotates a chart with the height of each bar.\n",
        "\n",
        "    Parameters:\n",
        "    - plot (matplotlib.pyplot): The matplotlib plot object.\n",
        "    - ax (Axes): The Axes object to annotate.\n",
        "    \"\"\"\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "\n",
        "        # Only annotate if height is significant, and avoid zero or near-zero annotations\n",
        "        if height > 0.001:\n",
        "            plot.annotate(f'{format(height, \".1f\")}% ',          # Annotate with 1 decimal places\n",
        "                          (p.get_x() + p.get_width() / 2., height),  # Position the annotation at the top of the bar\n",
        "                          ha='center', va='center',       # Center the annotation\n",
        "                          xytext=(0, 4),                  # Small offset to avoid overlapping with the bar\n",
        "                          textcoords='offset points')\n"
      ],
      "metadata": {
        "id": "fy_4SFcgBdz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_stacked_bar_with_annotations(df, x, y, normalize='index', figsize=(8, 6), show_legend=True,show_annot=True, ax=None):\n",
        "    \"\"\"\n",
        "    Creates a stacked bar plot with pastel colors and annotates each bar with proportion values.\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): The DataFrame containing the data.\n",
        "    - x (str): The column name to be used for the x-axis categories.\n",
        "    - y (str): The column name to be used for the y-axis categories.\n",
        "    - normalize (str, optional): Normalizes the values to proportions. Default is 'index'.\n",
        "    - figsize (tuple, optional): The size of the figure. Default is (8, 6).\n",
        "    - show_legend (bool, optional): Whether to show the legend. Default is True.\n",
        "    - ax (matplotlib.axes.Axes, optional): An existing axes object for plotting. Default is None.\n",
        "\n",
        "    Returns:\n",
        "    - ax (matplotlib.axes.Axes): The axes object containing the plot.\n",
        "    \"\"\"\n",
        "    # Create the crosstab\n",
        "    crosstab = pd.crosstab(df[x], df[y], normalize=normalize) * 100\n",
        "    crosstab.round(1)\n",
        "    # Create the plot on the provided ax or create a new one if ax is None\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    crosstab.plot(kind='bar', stacked=True, ax=ax, color=['#66c2a5', '#fc8d62'])\n",
        "\n",
        "    # Add labels to the axes\n",
        "    formatted_string = ' '.join(word.capitalize() for word in x.split('_'))\n",
        "    ax.set_xlabel(formatted_string)\n",
        "    ax.set_ylabel('Proportion' if normalize else 'Count')\n",
        "    ax.set_title(f'Proportion of {y} by {x}' if normalize else f'Count of {y} by {x}')\n",
        "\n",
        "    # Annotate the bars with proportion or count values\n",
        "    if show_annot:\n",
        "      for container in ax.containers:\n",
        "          ax.bar_label(container, label_type='center', fmt='%.1f', labels=[f'{v:.1f}' if v > 0 else '' for v in container.datavalues])\n",
        "\n",
        "\n",
        "    # Show or remove the legend based on the show_legend parameter\n",
        "    if not show_legend:\n",
        "        ax.legend().remove()\n",
        "\n",
        "    return ax"
      ],
      "metadata": {
        "id": "k0wmVtW_iLSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_stacked_bar_subplots(df, columns, y, n_cols=2):\n",
        "    \"\"\"\n",
        "    Creates stacked bar subplots for the specified columns with a common legend.\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): The DataFrame containing the data.\n",
        "    - columns (list): List of column names to plot on the x-axis.\n",
        "    - y (str): The column name to plot on the y-axis.\n",
        "    - n_cols (int, optional): Number of columns for the subplot layout (default is 2).\n",
        "    \"\"\"\n",
        "    n_rows = (len(columns) + n_cols - 1) // n_cols  # Calculate the number of rows needed\n",
        "\n",
        "    # Create a figure with adjusted size\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 5))\n",
        "\n",
        "    # Flatten the axes array for easy iteration\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Loop through each column and create a subplot for it\n",
        "    for i, col in enumerate(columns):\n",
        "        ax = axes[i]  # Get the correct axis\n",
        "        plot_stacked_bar_with_annotations(df=df, x=col, y=y, ax=ax,show_legend=False)\n",
        "\n",
        "    # Hide any unused axes\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    # Get the handles and labels from one of the plots (to add the common legend)\n",
        "    handles, labels = axes[0].get_legend_handles_labels()\n",
        "\n",
        "    # Add a common legend below the subplots\n",
        "    fig.legend(handles, labels, loc='lower center', ncol=2, bbox_to_anchor=(0.5, -0.05))\n",
        "\n",
        "    # Adjust layout to avoid overlap\n",
        "    plt.tight_layout(pad=3.0, h_pad=3.0, w_pad=3.0)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "91lQEMBQosur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_boxplot(df, x_col, y_col, hue_col=None, title=None, xlabel=None, figsize=(8, 5), xticks_rotation=90):\n",
        "    \"\"\"\n",
        "    Creates a box plot to visualize the relationship between variables.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pandas DataFrame containing the data.\n",
        "    - x_col: str, column name for the x-axis.\n",
        "    - y_col: str, column name for the y-axis.\n",
        "    - hue_col: str, column name for grouping by color (optional).\n",
        "    - title: str, title of the plot (optional).\n",
        "    - xlabel: str, label for the x-axis (optional).\n",
        "    - figsize: tuple, size of the figure (default is (8, 5)).\n",
        "    - xticks_rotation: int, rotation angle for x-axis tick labels (default is 90).\n",
        "      Returns:\n",
        "    - plt (matplotlib.pyplot): The matplotlib plot object with annotations.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=figsize)  # Set the figure size\n",
        "    bxp = sns.boxplot(data=df, x=x_col, y=y_col, hue=hue_col,palette=\"Set2\")  # Create the box plot\n",
        "\n",
        "    if xlabel:\n",
        "        bxp.set_xlabel(xlabel)  # Set x-axis label if provided\n",
        "    if title:\n",
        "        bxp.axes.set_title(title)  # Set the plot title if provided\n",
        "\n",
        "    plt.xticks(rotation=xticks_rotation)  # Rotate x-axis labels\n",
        "    return plt\n"
      ],
      "metadata": {
        "id": "uLAH5GmXZ_qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_box_plot_with_legend(df, x, xlabel, color='red'):\n",
        "    \"\"\"\n",
        "    Draws a box plot with a vertical line indicating the mean value and includes a legend.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pandas.DataFrame): The DataFrame containing the data to plot.\n",
        "    - x (str): The name of the column in the DataFrame to be plotted.\n",
        "    - xlabel (str): The label for the x-axis.\n",
        "    - color (str, optional): The color of the box plot. Default is 'red'.\n",
        "\n",
        "    Returns:\n",
        "    - plt (matplotlib.pyplot): The matplotlib pyplot object for further customization or saving.\n",
        "    \"\"\"\n",
        "    mean_value = df[x].mean()\n",
        "    sns.boxplot(data=df, x=x, color=color)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.axvline(mean_value, color='green', linestyle=':', label=f'Mean: {mean_value:.2f}')\n",
        "    plt.legend()\n",
        "    return plt"
      ],
      "metadata": {
        "id": "9uPpARyAmQCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_box_plot_side_by_side(df, x, xlabel, category_col, color='red'):\n",
        "    \"\"\"\n",
        "    Plots side-by-side box plots for different categories in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pandas.DataFrame): The DataFrame containing the data to plot.\n",
        "    - x (str): The name of the column in the DataFrame to be plotted.\n",
        "    - xlabel (str): The label for the x-axis.\n",
        "    - category_col (str): The column name in the DataFrame used to categorize the data.\n",
        "    - color (str, optional): The color of the box plot. Default is 'red'.\n",
        "\n",
        "    Returns:\n",
        "    - plt (matplotlib.pyplot): The matplotlib pyplot object for further customization or saving.\n",
        "    \"\"\"\n",
        "    # Extract unique categories\n",
        "    categories = df[category_col].unique()\n",
        "\n",
        "    # Create subplots with 1 row and the number of columns equal to the number of categories\n",
        "    fig, axes = plt.subplots(1, len(categories), figsize=(12, 6))\n",
        "\n",
        "    # Loop over each category and plot\n",
        "    for i, category in enumerate(categories):\n",
        "        plt.sca(axes[i])  # Set the current axes\n",
        "        subset = df[df[category_col] == category]\n",
        "        draw_box_plot_with_legend(subset, x, xlabel, color=color)\n",
        "        axes[i].set_title(f'{category.capitalize()}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return plt"
      ],
      "metadata": {
        "id": "PFr_HD4cqAzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_catplot_with_annotations(df, x, hue, col, colors, height=4, aspect=1, title=\"Catplot with Annotations\", annotation_color='b'):\n",
        "    \"\"\"\n",
        "    Creates a catplot with count kind, a color palette, axis labels, title, and annotations.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The DataFrame containing the data.\n",
        "    x (str): The name of the column for the x-axis.\n",
        "    hue (str): The name of the column for hue.\n",
        "    col (str): The name of the column for creating subplots.\n",
        "    colors (tuple): A tuple of two colors for the palette.\n",
        "    height (int): The height of each facet (default is 4).\n",
        "    aspect (float): Aspect ratio of each facet (default is 1).\n",
        "    title (str): The title of the plot (default is \"Catplot with Annotations\").\n",
        "    annotation_color (str): The color of the annotations (default is 'b').\n",
        "    \"\"\"\n",
        "    # Create the catplot\n",
        "    catplot = sns.catplot(data=df, x=x, hue=hue, col=col, kind='count', height=height, aspect=aspect, palette=colors)\n",
        "\n",
        "    # Set axis labels and title\n",
        "    catplot.set_axis_labels(x, 'Count')\n",
        "    catplot.set_titles(col_template=\"{col_name}\")\n",
        "    catplot.fig.suptitle(title, y=1.02)  # Title with a bit of padding\n",
        "\n",
        "    # Add annotations with specified color\n",
        "    for ax in catplot.axes.flat:\n",
        "        for p in ax.patches:\n",
        "            height = p.get_height()\n",
        "            ax.annotate(f'{height}', (p.get_x() + p.get_width() / 2, height),\n",
        "                        ha='center', va='center', xytext=(0, 10), textcoords='offset points',\n",
        "                        color=annotation_color)"
      ],
      "metadata": {
        "id": "KjsozUBBTbu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def distribution_plot_wrt_target(data, predictor, target, xlabel1=None, xlabel2=None, showhistogram=False,figsize=(12,8)):\n",
        "    \"\"\"\n",
        "    Plots the distribution of a predictor variable with respect to a target variable.\n",
        "\n",
        "    This function creates a 2x2 grid of plots, including:\n",
        "    1. Histograms with KDE for each unique value of the target variable (if showhistogram=True).\n",
        "    2. A boxplot showing the distribution of the predictor variable grouped by the target variable.\n",
        "    3. A boxplot showing the distribution of the predictor variable grouped by the target variable without outliers.\n",
        "\n",
        "    Parameters:\n",
        "    - data (DataFrame): The input DataFrame containing the data.\n",
        "    - predictor (str): The name of the predictor variable (column) to visualize.\n",
        "    - target (str): The name of the target variable (column) to group the data by.\n",
        "    - xlabel1 (str): Label for the x-axis of the first histogram.\n",
        "    - xlabel2 (str): Label for the x-axis of the second histogram.\n",
        "    - showhistogram (bool): If True, histograms with KDE plots will be displayed.\n",
        "\n",
        "    Returns:\n",
        "    - None: Displays the plots but does not return any values.\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axs = plt.subplots(2, 2, figsize=figsize)\n",
        "    target_uniq = data[target].unique()\n",
        "\n",
        "    if showhistogram:\n",
        "        # Histogram for the first unique target value\n",
        "        axs[0, 0].set_title(\"Distribution of \" + predictor + \" for target=\" + str(target_uniq[0]))\n",
        "        sns.histplot(\n",
        "            data=data[data[target] == target_uniq[0]],\n",
        "            x=predictor,\n",
        "            kde=True,\n",
        "            ax=axs[0, 0],\n",
        "            color=colors[0],\n",
        "            stat=\"density\",\n",
        "        )\n",
        "        axs[0, 0].set_xlabel(xlabel1)\n",
        "\n",
        "        # Histogram for the second unique target value\n",
        "        axs[0, 1].set_title(\"Distribution of \" + predictor + \" for target=\" + str(target_uniq[1]))\n",
        "        sns.histplot(\n",
        "            data=data[data[target] == target_uniq[1]],\n",
        "            x=predictor,\n",
        "            kde=True,\n",
        "            ax=axs[0, 1],\n",
        "            color=colors[1],\n",
        "            stat=\"density\",\n",
        "        )\n",
        "        axs[0, 1].set_xlabel(xlabel2)\n",
        "    else:\n",
        "        # If no histograms are shown, hide the first row\n",
        "        axs[0, 0].axis('off')\n",
        "        axs[0, 1].axis('off')\n",
        "\n",
        "    # Boxplot with outliers\n",
        "    axs[1, 0].set_title(\"Boxplot of \" + predictor + \" w.r.t \" + target)\n",
        "    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], color=colors[0])\n",
        "\n",
        "    # Boxplot without outliers\n",
        "    axs[1, 1].set_title(\"Boxplot (without outliers) of \" + predictor + \" w.r.t \" + target)\n",
        "    sns.boxplot(\n",
        "        data=data,\n",
        "        x=target,\n",
        "        y=predictor,\n",
        "        ax=axs[1, 1],\n",
        "        showfliers=False,\n",
        "        color=colors[1],\n",
        "        showmeans=True\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "zfclVefccftJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to compute different metrics to check performance of a classification model built using statsmodels\n",
        "def model_performance_classification_sklearn(\n",
        "    model, predictors, target, threshold=0.5\n",
        "):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    threshold: threshold for classifying the observation as class 1\n",
        "    \"\"\"\n",
        "\n",
        "    # checking which probabilities are greater than threshold\n",
        "    pred_temp = (model.predict_proba(predictors))[:, 1] > threshold\n",
        "    # rounding off the above values to get classes\n",
        "    pred = np.round(pred_temp)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred)  # to compute Recall\n",
        "    precision = precision_score(target, pred)  # to compute Precision\n",
        "    f1 = f1_score(target, pred)  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ],
      "metadata": {
        "id": "k73YQ275n_Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to plot the confusion_matrix of a classification model\n",
        "def confusion_matrix_sklearn(model, predictors, target, title, threshold=0.5):\n",
        "    \"\"\"\n",
        "    To plot the confusion_matrix with percentages.\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    threshold: threshold for classifying the observation as class 1\n",
        "    \"\"\"\n",
        "    # Checking which probabilities are greater than threshold\n",
        "    pred_temp = (model.predict_proba(predictors))[:, 1] > threshold\n",
        "    # Rounding off the above values to get classes\n",
        "    y_pred = np.round(pred_temp)\n",
        "\n",
        "    cm = confusion_matrix(target, y_pred)\n",
        "\n",
        "    # Create labels with counts and percentages\n",
        "    labels = np.asarray(\n",
        "        [\n",
        "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
        "            for item in cm.flatten()\n",
        "        ]\n",
        "    ).reshape(cm.shape)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\", cmap=pellete)\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")\n",
        "    plt.title(title)  # Add a title\n",
        "    plt.show()  # Show the plot"
      ],
      "metadata": {
        "id": "VRhVMR4_pBHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_dataset_shapes_and_class_distribution(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Print the shapes of training and test datasets, along with the percentage of classes in each set.\n",
        "\n",
        "    Parameters:\n",
        "    X_train (DataFrame): Training feature set.\n",
        "    X_test (DataFrame): Test feature set.\n",
        "    y_train (Series): Training target set.\n",
        "    y_test (Series): Test target set.\n",
        "    \"\"\"\n",
        "    # Shape of Test and Train Data\n",
        "    print(\"Shape of Training set:\", X_train.shape)\n",
        "    print(\"Shape of Test set:\", X_test.shape)\n",
        "\n",
        "    # Percentage of classes in training set\n",
        "    print(\"\\nPercentage of classes in Training set:\")\n",
        "    print(y_train.value_counts(normalize=True))\n",
        "\n",
        "    # Percentage of classes in test set\n",
        "    print(\"\\nPercentage of classes in Test set:\")\n",
        "    print(y_test.value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "zW0S1lJhxWD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_model_performance(train_performance, test_performance, model_names, mode='both'):\n",
        "    \"\"\"\n",
        "    Combines and compares training and test performance metrics for models.\n",
        "\n",
        "    Parameters:\n",
        "    - train_performance (list of DataFrames): A list of DataFrames containing training performance metrics.\n",
        "    - test_performance (list of DataFrames): A list of DataFrames containing test performance metrics.\n",
        "    - model_names (list of str): List of model names or descriptions for labeling columns.\n",
        "    - mode (str): Mode of comparison, either 'both' (default), 'train', or 'test'.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: A DataFrame combining the performance metrics for comparison.\n",
        "    \"\"\"\n",
        "\n",
        "    # Concatenate training and test performance DataFrames\n",
        "    if mode == 'both':\n",
        "        train_df = pd.concat(train_performance, axis=1)\n",
        "        test_df = pd.concat(test_performance, axis=1)\n",
        "\n",
        "        # Add model names as column labels\n",
        "        train_df.columns = [f\"{name} (Train)\" for name in model_names]\n",
        "        test_df.columns = [f\"{name} (Test)\" for name in model_names]\n",
        "\n",
        "        # Combine train and test into one DataFrame\n",
        "        combined_df = pd.concat([train_df, test_df], keys=['Train', 'Test'], axis=1)\n",
        "    elif mode == 'train':\n",
        "        combined_df = pd.concat(train_performance, axis=1)\n",
        "        combined_df.columns = model_names\n",
        "    elif mode == 'test':\n",
        "        combined_df = pd.concat(test_performance, axis=1)\n",
        "        combined_df.columns = model_names\n",
        "\n",
        "    return combined_df"
      ],
      "metadata": {
        "id": "IFuvxupfpbQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printmodelscoreandtrainTime(model,X_train,y_train,X_test,y_test,training_time):\n",
        "  print(f\"Training Score {model.score(X_train,y_train)}\")\n",
        "  print(f\"Testing Score {model.score(X_test,y_test)}\")\n",
        "  print(f\"Training Time {training_time}\")"
      ],
      "metadata": {
        "id": "9wLoIph9wjDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to wrap the training process\n",
        "def train_model(model,Xtrain,ytrain):\n",
        "    model.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "Cl317lfPnEi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing no of values in each of these catgorical variable\n",
        "for col in catgoricalcol:\n",
        "  print(f'No of values in each {col}:')\n",
        "  print(ezdf[col].value_counts(normalize=True)*100)"
      ],
      "metadata": {
        "id": "MEvyKAcsng2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart on continent to see number of application on each\n",
        "plot_bar_chart_percentage(ezdf,'continent','Continent',pellete=pellete)"
      ],
      "metadata": {
        "id": "Ear3Qa4qsrLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Highest number of visa applications are from Asia (66%) followed by Eurupe(14.6%) and North America (12.9%)\n",
        "- Oceania is least number visa application which is only (0.8%).South Africa and Africa also does not have much visa applications"
      ],
      "metadata": {
        "id": "YoRdGYLutqGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart on education_of_employee to check which degree has highest visa application\n",
        "plot_bar_chart_percentage(ezdf,'education_of_employee','Education Of Employee',pellete=pellete)"
      ],
      "metadata": {
        "id": "KkDNgVx8uXp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "The majority of the applicants have a Bachelor's degree (40%) followed by masters degree 37.8% while a small portion of them either have a doctorate (8.6%) or high school degree (13.4%)"
      ],
      "metadata": {
        "id": "CB8IQcVQNuP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_bar_chart_percentage(ezdf,'region_of_employment','Employemnet Region',pellete=pellete)"
      ],
      "metadata": {
        "id": "5Zt5A2Y_xEAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Most of the visa applications for Northeast Region(28%) followed by south (27%) and west(25%)\n",
        "- Island has lowest visa application around 1.5%"
      ],
      "metadata": {
        "id": "KTnNz5xBxZY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart on prior job exp among applicants\n",
        "plot_bar_chart_percentage(ezdf,'has_job_experience','Has Job Exp',pellete=pellete)"
      ],
      "metadata": {
        "id": "o-fJWKmavatL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "The majority of the applicants have relevant job exp (58.1%) where as 41.9% doesnot have prior exp .It will be intresting to see if this field has any effect on the approval or certified."
      ],
      "metadata": {
        "id": "HbnQVkcFORkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart on wage rate of employee\n",
        "plot_bar_chart_percentage(ezdf,'unit_of_wage','Unit Of Wage',pellete=pellete)"
      ],
      "metadata": {
        "id": "tW1lIw1kvpxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Most of the applicants are for yearly wage (90.1%) followed by 8.5% who are having hourly wage.\n",
        "- Weekly monthly has very limited number of applicants.\n"
      ],
      "metadata": {
        "id": "vSgiM52oO3qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart on education_of_employee to check which degree has highest visa application\n",
        "plot_bar_chart_percentage(ezdf,'full_time_position','Full Time Position',pellete=pellete)"
      ],
      "metadata": {
        "id": "cxL4IGDcwFzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "Most of the applicants are applying for full time positions(89%)"
      ],
      "metadata": {
        "id": "qTNbunr5UziY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart on to see how many applicants applied who requires trainings vs who does not\n",
        "plot_bar_chart_percentage(ezdf,'requires_job_training','Require Training',pellete=pellete)"
      ],
      "metadata": {
        "id": "hJcHlzEfYV2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "Most of the applicant (88%) does not need trainings .We believe thats due to the fact that most of them had prior exp"
      ],
      "metadata": {
        "id": "hglAjHqWY2rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart on case staus approval\n",
        "plot_bar_chart_percentage(ezdf,'case_status','Case Status',pellete=pellete)"
      ],
      "metadata": {
        "id": "hOaD1uRawtPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "Around 66.8% of visa applications are certified and around 33% are denied .We might have to check what parameters are affecting the approval"
      ],
      "metadata": {
        "id": "UXMebvW7U93Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram and boxplot for distribution of prevailing_wage\n",
        "\n",
        "plot_histogram_and_boxplot(df=ezdf,column='no_of_employees',xlabel='no_of_employees',ylabel='Distribution of Total Workers',title='Distribution of Total Workers')"
      ],
      "metadata": {
        "id": "48YwzpA61vSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Min no of employees in a orgnisation is 11 who applied for visa .The max value is above .6 million where as 75th percentile is around 3504.\n",
        "Either there a big orgnaisation who has apllied visa for its employee or the entry is wrong .\n",
        "-  This field has so many outliers."
      ],
      "metadata": {
        "id": "6FYBWTeSHx-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram and boxplot for distribution of yr_of_estab\n",
        "\n",
        "plot_histogram_and_boxplot(df=ezdf,column='yr_of_estab',xlabel='yr_of_estab',ylabel='Distribution on Year Of Establishment',title='Distribution on Year Of Establishment')"
      ],
      "metadata": {
        "id": "DMMYr0YtHxpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- The distribution is skewed towards left.Some of the organisation  established before 1800 and max value for this field is 2016"
      ],
      "metadata": {
        "id": "hKIj1UCrIeZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram and boxplot for distribution of prevailing_wage\n",
        "plot_histogram_and_boxplot(df=ezdf,column='prevailing_wage',xlabel='prevailing_wage',ylabel='Distribution On Prevailing Wage',title='Distribution On Prevailing Wage')"
      ],
      "metadata": {
        "id": "zNwfIBSEIf--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- The dataset is skewed towards right .There are many outliers for this column as the max wage ranging to 319210.27.Which is quite higher then 75 percentile of the data (107735)\n",
        "- The mean of this column is around 74455.81"
      ],
      "metadata": {
        "id": "FppdZGFnLSLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Stack bar chart for continent and case stattus\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='continent',y='case_status');"
      ],
      "metadata": {
        "id": "amZltjUvloK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "**Overall Certification vs. Denial Rates:**\n",
        "\n",
        "- The proportion of Certified cases varies significantly across continents, ranging from a high of 79.2% in Europe to a low of 57.9% in South America.\n",
        "Denial rates also fluctuate across continents, with South America having the highest denial rate at 42.1%, while Europe has the lowest at 20.8%.\n",
        "\n",
        "- Africa has a relatively high certification rate at 72.1%, but it is still lower than Europe.\n",
        "- Asia shows  65.3% Certified cases and a denial rate of 34.7%.(This is still better considering most of visa applications are from asia around 66%\n",
        "- North America has a   61.9% Certified and 38.1% Denied, reflecting a higher denial rate compared to Europe and Asia.\n",
        "- Oceania has a slightly better certification rate than North America, with 63.5% Certified and 36.5% Denied.(But this has least number of visa applications)\n",
        "\n"
      ],
      "metadata": {
        "id": "EMvSDbSaO55C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf.groupby('education_of_employee')['prevailing_wage'].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "tg8ZUm7Y6Acu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Master has highest prevailing wage followed by masters\n",
        "- Doctorate has lowest prevailing wage\n"
      ],
      "metadata": {
        "id": "c3A93AaR6Yak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack bar chart vs education of employees\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='education_of_employee',y='case_status');"
      ],
      "metadata": {
        "id": "wkDB3J-pmpPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "-  Doctorate has highest acceptance(Least applicants)  rate around 87.2% followed by masters and bachelors which has highest applications as well.\n",
        "- People with high school education has highest rejection rate may be due to lack of skills and may be lack of much opprutunity"
      ],
      "metadata": {
        "id": "ZESRrLUBSlnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack bar chart has job exp vs certified or not\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='has_job_experience',y='case_status');"
      ],
      "metadata": {
        "id": "qXsMOONAm8sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "Applicants with job experience have a ratio of approved to denied applications of 3:1(75%:25%) approx, whereas the ratio for applicants without job experience have around a 5:4(56%:43%) ratio."
      ],
      "metadata": {
        "id": "mnzOk7blXhoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack bar chart to see the propertion on training on job vs case status\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='requires_job_training',y='case_status');"
      ],
      "metadata": {
        "id": "ab9jujc_nEHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Applicants who does need trainings are having more certified rate then who does not need .But around 88% applicants does not need trainings which is quite big number so we cann not say pople who need job training has higher acceptance rate."
      ],
      "metadata": {
        "id": "f2wBDnZjYAfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_stacked_bar_with_annotations(df=ezdf,x='region_of_employment',y='case_status');"
      ],
      "metadata": {
        "id": "OTfXEjUfnPDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- There are more  case which are certified (76%) in Midwest .Rejection is quite law for this region of employment followed by South(30) and Northeast(37.1)\n",
        "The above regions have higher applicants as well\n",
        "\n",
        "\n",
        "---\n",
        "No of Applicants:\n",
        "\n",
        "| **Employment Region** | **Percentage** |\n",
        "|-----------------------|----------------|\n",
        "| Island                | 1.5%           |\n",
        "| Midwest               | 16.9%          |\n",
        "| Northeast             | 28.2%          |\n",
        "| South                 | 27.5%          |\n",
        "| West                  | 25.8%          |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8SJIG8X5lubt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_stacked_bar_with_annotations(df=ezdf,x='unit_of_wage',y='case_status');"
      ],
      "metadata": {
        "id": "9FG7QZfbnaHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Applicants with yearly wage has highest certified rate (70%) followed by month (62%) and week(62%) even most applicants who applied for visa are looking for yearly wage (90%).So there is a tendency to prefer applicants who looking for yearly wage compared to others.\n",
        "- Approval is quite less for applicants who are looking for hourly wage.We might to check further on the prevailing_wage part of hourly rate are more compared to others."
      ],
      "metadata": {
        "id": "DDImyGgmXSut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf.groupby('unit_of_wage')['prevailing_wage'].mean().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "g5BCT4l6gaI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- It seems like unit of wage per hour is quite high if we consider hourly rate (considering each day 8 hours) if we compared with other unit of wage like month,week and year.\n",
        "- Mean value for month,week and year are quite similar.\n"
      ],
      "metadata": {
        "id": "N3VOONkkcQ-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack bar chart full time position vs case status\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='full_time_position',y='case_status');"
      ],
      "metadata": {
        "id": "WV4V9TSpno3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- There is not much difference on visa approval or denied based on position (full time or not)\n",
        "- There is a little difference we observed though  non full time position has more certified rate around (68%) compared to (66%) for fulltime .But again most of the applicants are applied for full time.\n"
      ],
      "metadata": {
        "id": "vvAKKBzM_mKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Partition data in years bin to understand more  if comapany age anything to do with approval\n",
        "bins = [0, 10, 20, 30, 50, 100,200]  # Years of company age\n",
        "names = ['0-10', '10-20', '20-30', '30-50', '50-100','100+']\n",
        "currentyear=2024\n",
        "ezdf['no_of_year_old']=currentyear-ezdf['yr_of_estab']\n",
        "ezdf['years']=pd.cut(ezdf['no_of_year_old'], bins=bins, labels=names)"
      ],
      "metadata": {
        "id": "bRK8Duh9J0Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack bar chart after binning those in to differnet bins\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='years',y='case_status');"
      ],
      "metadata": {
        "id": "NoHTcwmqN32Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- There is not much relation with respect to company age and visa certified .Most of the approval rate ranging from (64-70).\n"
      ],
      "metadata": {
        "id": "GEuuMwZ1ff13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Partition data in years bin to understand more  if comapany size anything to do with approval\n",
        "\n",
        "bins = [0,200,500,1000,10000,45000]\n",
        "names = ['0-200','200-500','500-1000','1000-10000','10000+']\n",
        "ezdf['size_of_cmny']=pd.cut(ezdf['no_of_employees'],bins=bins,labels=names)\n",
        "ezdf['size_of_cmny'].value_counts( normalize=False)"
      ],
      "metadata": {
        "id": "DNicWwZ2O-XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stack bar chart size of organisation vs visa certified or not\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='size_of_cmny',y='case_status');"
      ],
      "metadata": {
        "id": "Y9ZgWjU6ZwSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- There is not much relation with respect to company size and visa certified .Most of the approval rate ranging from (63-67) approx.\n"
      ],
      "metadata": {
        "id": "UDLUKkOij_Uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plot to check the distribution of wage  for both denied and certified\n",
        "plot_box_plot_side_by_side(df=ezdf,x='prevailing_wage',xlabel='prevailing_wage',category_col='case_status',color=colors[0]);"
      ],
      "metadata": {
        "id": "y0ATK1ZConRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "Applicants who are certified or got their visa approved have higher mean prevailing wage"
      ],
      "metadata": {
        "id": "DuCaAsI96_Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf.groupby('region_of_employment')['prevailing_wage'].mean()"
      ],
      "metadata": {
        "id": "NbTMZ05olHda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_boxplot(df=ezdf,x_col='prevailing_wage',y_col='region_of_employment',hue_col='region_of_employment',title='Wage Region Wise',xlabel='Wage');"
      ],
      "metadata": {
        "id": "K7MBuw-Dnt4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Midwest and island have higher wage (92000 approx) compared to other region.\n",
        "- Northeast has lowest wage (68000 approx) compared to other region.\n",
        "\n"
      ],
      "metadata": {
        "id": "0h9KU2eGwR6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf.groupby('continent')['prevailing_wage'].mean()"
      ],
      "metadata": {
        "id": "3ShXwMvCWnRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_boxplot(df=ezdf,x_col='prevailing_wage',y_col='continent',hue_col='continent',title='Wage Continent',xlabel='Wage');"
      ],
      "metadata": {
        "id": "73URxtwgC6ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Africa and Asia applicants mean prevailing_wage is higher then other regions"
      ],
      "metadata": {
        "id": "7uu3r5OEWurn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping columns which we had created for our analysis\n",
        "ezdf.drop(['no_of_year_old','years','size_of_cmny'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "sodxYuitByP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the numerical columns\n",
        "numerical_columns = ezdf[ezdf.select_dtypes(exclude = 'category').columns[1:]]\n",
        "\n",
        "# Find the correlation between the numerical columns\n",
        "correlation_matrix = numerical_columns.corr()\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(correlation_matrix)\n",
        "# Create a heatmap using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=pellete, fmt=\".2f\", linewidths=0.5)\n",
        "\n",
        "# Set heatmap title\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "\n",
        "# Show the heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eEgCXCEnBhdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "There is no corelation between differnet numerical features"
      ],
      "metadata": {
        "id": "k5YAOtc0DcdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA QUESTIONS"
      ],
      "metadata": {
        "id": "jNSnkRtH-fy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Those with higher education may want to travel abroad for a well-paid job. Does education play a role in Visa certification?"
      ],
      "metadata": {
        "id": "X_QfqYwi-Waj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack bar chart vs education of employees\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='education_of_employee',y='case_status');"
      ],
      "metadata": {
        "id": "KfH599scL6TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=ezdf.groupby('education_of_employee')['case_status'].value_counts()\n",
        "df"
      ],
      "metadata": {
        "id": "1Pi5cB-fMh3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack bar chart vs education of employees\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='education_of_employee',y='case_status');"
      ],
      "metadata": {
        "id": "o_QytcFLN6md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "As the bar plot  aboves shows, the propertion of applications being certified versus denied increases considerably as an applicant's highest level of education achieved increases.\n",
        "- Doctorate has highest certified rate and highschool has lowest approval\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TP_GQ-vzLRi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How does the visa status vary across different continents?\n"
      ],
      "metadata": {
        "id": "3LO8HZd-OnQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#group data by continent and count the numbers of each case_status for each category\n",
        "ezdf.groupby('continent')['case_status'].value_counts()\n"
      ],
      "metadata": {
        "id": "g-EULJ7RO7He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Stack bar chart for continent and case stattus\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='continent',y='case_status');"
      ],
      "metadata": {
        "id": "ozqL6jViOyJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "**Overall Certification vs. Denial Rates:**\n",
        "- The proportion of Certified cases varies significantly across continents, ranging from a high of 79.2% in Europe to a low of 57.9% in South America. Denial rates also fluctuate across continents, with South America having the highest denial rate at 42.1%, while Europe has the lowest at 20.8%.\n",
        "\n",
        "- Africa has a relatively high certification rate at 72.1%, but it is still lower than Europe.\n",
        "\n",
        "- Asia shows 65.3% Certified cases and a denial rate of 34.7%.(This is still better considering most of visa applications are from asia around 66%\n",
        "\n",
        "- North America has a 61.9% Certified and 38.1% Denied, reflecting a higher denial rate compared to Europe and Asia.\n",
        "\n",
        "- Oceania has a slightly better certification rate than North America, with 63.5% Certified and 36.5% Denied.(But this has least number of visa applications)\n"
      ],
      "metadata": {
        "id": "Nvbg1P8BO-jq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experienced professionals might look abroad for opportunities to improve their lifestyles and career development. Does work experience influence visa status?"
      ],
      "metadata": {
        "id": "pPmvrZ7EPrld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#group data by has_job_experience and count the numbers of each case_status\n",
        "ezdf.groupby('has_job_experience')['case_status'].value_counts()"
      ],
      "metadata": {
        "id": "wNvWSgV-PugK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack bar chart has job exp vs certified or not\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='has_job_experience',y='case_status');"
      ],
      "metadata": {
        "id": "oSwCG4oWP3Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "Applicants with job experience have a ratio of approved to denied applications of 3:1(75%:25%) approx, whereas the ratio for applicants without job experience have around a 5:4(56%:43%) ratio."
      ],
      "metadata": {
        "id": "bRx3-e03QA38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### In the United States, employees are paid at different intervals. Which pay unit is most likely to be certified for a visa?"
      ],
      "metadata": {
        "id": "BT3fSqGPQP33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot bar chart for unit of wage and visa approved or denied\n",
        "plot_stacked_bar_with_annotations(df=ezdf,x='unit_of_wage',y='case_status');"
      ],
      "metadata": {
        "id": "WvJq9TaQQy6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Applicants with yearly wage has highest certified rate (70%) followed by month (62%) and week(62%) even most applicants who applied for visa are looking for yearly wage (90%).So there is a tendency to prefer applicants who looking for yearly wage compared to others.\n",
        "- Approval is quite less for applicants who are looking for hourly wage.We have covered in EDA how hourly rate is more compared to others."
      ],
      "metadata": {
        "id": "t-IzQEq-RPSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The US government has established a prevailing wage to protect local talent and foreign workers. How does the visa status change with the prevailing wage?"
      ],
      "metadata": {
        "id": "LxIUMnQwQjGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hostogram with box plot to show prevaling wage w.r.t visa status\n",
        "distribution_plot_wrt_target(data=ezdf,predictor='prevailing_wage',target='case_status',showhistogram=True,figsize=(12,8))"
      ],
      "metadata": {
        "id": "LmnKIEYZQlgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "The prevailing_wage (median and mean) is little bit higher for certified case .We have covered detailed analsyis in genral EDA with region_of_employment and continent aswell.\n"
      ],
      "metadata": {
        "id": "VKPbi2g5VCyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation For Modeling\n"
      ],
      "metadata": {
        "id": "DUnQpRjuXcAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outlier Detection and Treatment"
      ],
      "metadata": {
        "id": "MCqj9osqQQDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_col = ezdf.select_dtypes(include=np.number).columns.tolist()\n",
        "plt.figure(figsize=(30, 20))\n",
        "\n",
        "for i, variable in enumerate(numerical_col):\n",
        "    plt.subplot(5, 4, i + 1)\n",
        "    plt.boxplot(ezdf[variable], whis=1.5)\n",
        "    plt.tight_layout()\n",
        "    plt.title(variable)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lKrkOj8wKnWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation:\n",
        "Outliers present for no_of_employess,yr_of_estab and prevailing_wage in the data, but we did not treat as they are considered as proper values\n"
      ],
      "metadata": {
        "id": "mbL6_t0TQRXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "vOUmj-SMQy_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We will make the case status field as integer with certified as 1 and declined as 0 before creating any model"
      ],
      "metadata": {
        "id": "A1K13K8fQ9wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ezdf['case_status']=ezdf.case_status.apply(lambda x: 1 if x=='Certified' else 0)"
      ],
      "metadata": {
        "id": "rQXyUdlhXbGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remove nagative no of employees as it does not make any sense"
      ],
      "metadata": {
        "id": "b_O1HgLKRJ8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take absolute of the no of employees to remove nagative\n",
        "ezdf['no_of_employees']=ezdf['no_of_employees'].apply(lambda x: abs(x))"
      ],
      "metadata": {
        "id": "Vqg3Z_2Kpyhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validating\n",
        "ezdf[ezdf['no_of_employees'] < 0].count()"
      ],
      "metadata": {
        "id": "4EN9A_1jU0d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validating\n",
        "print(pd.concat([ez_df,ezdf],axis=1)['case_status'].head(5))\n"
      ],
      "metadata": {
        "id": "P7kyOh2tRV4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping case_id\n",
        "ezdf.drop('case_id',inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "uVFRxlerWXxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Prediction Challenges:\n",
        "\n",
        "- **False Negative**: The model predicts that an applicant will not be approved for a visa, but in reality, the applicant is eligible and gets approved.\n",
        "  - **Impact**: This can lead to missed opportunities for deserving applicants, resulting in dissatisfaction and potential reputational damage for Easy Visa.\n",
        "- **False Positive**: The model predicts that an applicant will be approved for a visa, but in reality, the applicant is not eligible.\n",
        "\n",
        "   - **Impact**: This can result in the approval of unqualified applicants, which may compromise security and  lead to further complications in the visa process.This even has impact on overall economy as U.S companies canot fill creatical positions.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "   - Both types of errors are significant in the context of visa approvals, and minimizing them is crucial for maintaining the integrity of the visa process and ensuring fair treatment of applicants.\n",
        "   - We should either  go for optimising **F1** score which is harmonic mean of recall and precession or we should try to increase the **Precession** by minimising **FP** as approving visa to someone who does not really a deserving applicants subject to security risk (If Govt want that)\n",
        "   - Preffered way is to increase **F1** Score\n"
      ],
      "metadata": {
        "id": "1IunJU2hoaMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We divide the dataset in test and training set"
      ],
      "metadata": {
        "id": "pKI1z1n1hLH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=ezdf.drop('case_status',axis=1) # Features\n",
        "y=ezdf['case_status'] # Target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n"
      ],
      "metadata": {
        "id": "ca_-dFuKfuBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_dataset_shapes_and_class_distribution(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "8nQt1iEGhRA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to encode all the labels with the value between 0 and n_classes-1.\n",
        "For implementing this, we are going to use LabelEncoder of scikit learn library and even OneHotencoder fopr fields like continent,region_of_employment,units_of_wage  which are not ordinal fields.Fileds like education_of_employee and other binary type fields are suitable for LabelEncoder\n",
        "\n",
        "\n",
        "---\n",
        "#### We are doing encoding seperately for train and test data set .This is to avoid Data Leakage.Data leakage occurs when information from the test set influences the training process, which can lead to overly optimistic performance estimates.\n"
      ],
      "metadata": {
        "id": "BtkyoJ7teP1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode variables with label encoing where ever justified and use one hot encoding where ever required\n",
        "\n",
        "le=LabelEncoder()\n",
        "\n",
        "X_train['education_of_employee']=le.fit_transform(X_train['education_of_employee'])\n",
        "X_test['education_of_employee']=le.transform(X_test['education_of_employee'])\n",
        "\n",
        "X_train['has_job_experience']=le.fit_transform(X_train['has_job_experience'])\n",
        "X_test['has_job_experience']=le.transform(X_test['has_job_experience'])\n",
        "\n",
        "X_train['requires_job_training']=le.fit_transform(X_train['requires_job_training'])\n",
        "X_test['requires_job_training']=le.transform(X_test['requires_job_training'])\n",
        "\n",
        "X_train['full_time_position']=le.fit_transform(X_train['full_time_position'])\n",
        "X_test['full_time_position']=le.transform(X_test['full_time_position'])\n",
        "\n",
        "# Apply one-hot encoding on training and test data\n",
        "X_train = pd.get_dummies(X_train, columns=['continent', 'region_of_employment', 'unit_of_wage'])\n",
        "X_test = pd.get_dummies(X_test, columns=['continent', 'region_of_employment', 'unit_of_wage'])\n",
        "\n",
        "# Align columns in test set with train set (in case some categories are missing)\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "# Title for Test and Train\n",
        "cs_training=\"Confusion Matrix For Training\"\n",
        "cs_testing=\"Confusion Matrix For Testing\"\n"
      ],
      "metadata": {
        "id": "wiEwFeckb6gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Model Without Prunning"
      ],
      "metadata": {
        "id": "GNuNwD55mAyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Decision Tree Model with entropy without any prunning\n",
        "treemodel=DecisionTreeClassifier(criterion='entropy',random_state=1)\n",
        "# treemodel.fit(X_train,y_train)\n",
        "# Measure training time using timeit\n",
        "training_time_dt_default = timeit.timeit(lambda:train_model(treemodel,Xtrain=X_train,ytrain=y_train), number=1)"
      ],
      "metadata": {
        "id": "fN5k50s4ig-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing both train and test score\n",
        "printmodelscoreandtrainTime(model=treemodel,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_dt_default)"
      ],
      "metadata": {
        "id": "Ei3c7gRBp8yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- We see the model overfitted with training data\n",
        "- Training Time is low"
      ],
      "metadata": {
        "id": "mGpmG9odx0vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw Confusion matrix for test and train data\n",
        "confusion_matrix_sklearn(treemodel, X_train, y_train,cs_training)\n",
        "confusion_matrix_sklearn(treemodel, X_test, y_test,cs_testing)"
      ],
      "metadata": {
        "id": "x4zTdIFcwOSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 csore and recall\n",
        "dec_tree_performance_default=model_performance_classification_sklearn(model=treemodel, predictors=X_test, target=y_test)\n",
        "dec_tree_performance_default"
      ],
      "metadata": {
        "id": "NWZuzl6vrXud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- It seems with training data we have overfitted due to no prunning.\n",
        "- Plotting tree below we get a very complex model\n",
        "- Recall ,Precesion,F1 score is at 75% for test data .\n",
        "- Accuracy of model is below 70%"
      ],
      "metadata": {
        "id": "y4XCvjatsERe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "tree.plot_tree(treemodel,filled=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "66oMkujVdPsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obsevations:\n",
        "- Complex model is generated due to no prunning with overfitting"
      ],
      "metadata": {
        "id": "T8j2OZU_sW_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree with Post Prunning and max depth = 3"
      ],
      "metadata": {
        "id": "6o5nmDihsgNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Postpruning\n",
        "treemodel_pruned=DecisionTreeClassifier(max_depth=3)\n",
        "training_time_dt_pruned = timeit.timeit(lambda:train_model(treemodel_pruned,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "# Printing both train and test score\n",
        "printmodelscoreandtrainTime(model=treemodel_pruned,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_dt_pruned)"
      ],
      "metadata": {
        "id": "il61MhWPskGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We reduced the overfitting and accuracy score is improved.\n",
        "- Training Time is significantly lesser then the  default decision  tree as it went on to overfit the data"
      ],
      "metadata": {
        "id": "c76OW6EUyBa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Confusion Matrix on test data\n",
        "confusion_matrix_sklearn(treemodel_pruned, X_train, y_train,cs_training)\n",
        "confusion_matrix_sklearn(treemodel_pruned, X_test, y_test,cs_testing)"
      ],
      "metadata": {
        "id": "sxXaTGzTwt_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation: (On Test Set)\n",
        "- We have reduced the **FN** from 17% to 6.59%(Applicant was approved and the model predicted denial : False Negative (observed=1,predicted=0)\n",
        "-  **FP** is increased (observed=0,predicted=1) by prunning the tree"
      ],
      "metadata": {
        "id": "5txJ_h7pxLfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 csore and recall\n",
        "dec_tree_performance__prun_default=model_performance_classification_sklearn(model=treemodel_pruned, predictors=X_test, target=y_test)\n",
        "dec_tree_performance__prun_default"
      ],
      "metadata": {
        "id": "mPWFIEJTszsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- We have reduced the overfitting here with training data\n",
        "- **F1**  score is around  82%(Good) approx.\n",
        "- **Recall**  score is around  90% approx(This is quite Good).\n",
        "- **Precision** is at 75 % which is same as Decision Tree non prune\n",
        "-  **Accuracy** with test data is improved with post pruning 73%\n"
      ],
      "metadata": {
        "id": "LP7VNM3ztK3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Grid Value Search with Cv=3 (for validating 3 times)\n"
      ],
      "metadata": {
        "id": "A8q6D4A-yYJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Preprunning\n",
        "parameter={\n",
        " 'criterion':['gini','entropy','log_loss'],\n",
        "  'splitter':['best','random'],\n",
        "  'max_depth':[1,2,3,4,5],\n",
        "  'max_features':['auto', 'sqrt', 'log2']\n",
        "\n",
        "}\n",
        "# Create Tree model with decision tree\n",
        "treemodel_preprun=DecisionTreeClassifier()\n",
        "cv=GridSearchCV(treemodel_preprun,param_grid=parameter,cv=3,scoring='f1')"
      ],
      "metadata": {
        "id": "RKJMvecEvDay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit with training set\n",
        "cv.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "kL5ZO9Tkz-_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params=cv.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "n99Y-YS70JEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "After performing hyperparameter tuning using `GridSearchCV`, we found the best parameters for our Decision Tree Classifier as follows:\n",
        "\n",
        "- **Criterion**: `'entropy'`  \n",
        "  This criterion is used to measure the quality of a split in the decision tree. It uses information gain based on entropy, helping to determine the best possible splits for the tree.\n",
        "\n",
        "- **Max Depth**: `5`  \n",
        "  This limits the maximum depth of the decision tree. A maximum depth of 5 helps to control overfitting by restricting the model's complexity.\n",
        "\n",
        "- **Max Features**: `'log2'`  \n",
        "  This parameter specifies the number of features to consider when looking for the best split. By using `'log2'`, the model will only consider a logarithmic number of features at each split, which can help reduce overfitting and improve performance.\n",
        "\n",
        "- **Splitter**: `'best'`  \n",
        "  This parameter indicates the strategy used to choose the split at each node. Setting it to `'best'` means that the model will always choose the best possible split among the available features.\n",
        "\n",
        "These optimal parameters will enhance the performance of our Decision Tree Classifier, allowing it to generalize better on unseen data.\n"
      ],
      "metadata": {
        "id": "Ab1FtySX0LoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Decesion tree with those Hyper parameter and fit on training set\n",
        "best_model = DecisionTreeClassifier(**best_params)\n",
        "training_time_dt_tuned = timeit.timeit(lambda:train_model(best_model,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=best_model,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_dt_tuned)"
      ],
      "metadata": {
        "id": "e3Z8YA8B127g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Score decreased a bit compared post pruned model\n",
        "- We have reduced the overfitting\n",
        "- Training time is less too then previous two models(Default DT and Pruned DT)"
      ],
      "metadata": {
        "id": "flS3arIO42m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Confusion Matrix on test data and training\n",
        "confusion_matrix_sklearn(best_model, X_train, y_train,cs_training)\n",
        "confusion_matrix_sklearn(best_model, X_test, y_test,cs_testing)"
      ],
      "metadata": {
        "id": "xRyFndyH4Yza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- This model can predict more certified case compared to previous model**(TP)**\n",
        "- This model has more **FP** compared to previous models\n",
        "- **FN** are reduced a bit"
      ],
      "metadata": {
        "id": "B9NjEVeb53dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall\n",
        "dec_tree_performance__pre_prun_default=model_performance_classification_sklearn(model=best_model, predictors=X_test, target=y_test)\n",
        "dec_tree_performance__pre_prun_default"
      ],
      "metadata": {
        "id": "55XjJDs25ws-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- With Grid Search CV the **F1** score is now at 81%\n",
        "- With Grid Search CV the **Recall**  is now at 92% which is improved from post prunning model.\n",
        "- Acuracy of the model is dropped from post pruned model"
      ],
      "metadata": {
        "id": "b8wDLSsw58k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot hyper tune model\n",
        "plt.figure(figsize=(15,10))\n",
        "tree.plot_tree(treemodel_pruned,filled=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RDg1qpf2H9Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get features imprtance from the model\n",
        "importances=treemodel_pruned.feature_importances_\n",
        "# Create a DataFrame for better visualization\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': importances\n",
        "})\n",
        "# Sort the DataFrame by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print the important parameters\n",
        "print(\"Important Features from Decision Tree:\")\n",
        "print(feature_importance_df)"
      ],
      "metadata": {
        "id": "QigoyWwI58NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "Important Features from Decision Tree\n",
        "\n",
        "After evaluating the feature importances from our pruned Decision Tree model, we found the following features to have non-zero importance in predicting the outcome:\n",
        "\n",
        "| Feature                      | Importance |\n",
        "|------------------------------|------------|\n",
        "| education_of_employee        | 0.570679   |\n",
        "| unit_of_wage_Hour           | 0.293074   |\n",
        "| has_job_experience           | 0.136247   |\n",
        "\n",
        "These features significantly contribute to the model's decision-making process. The majority of the other features were found to have zero importance, indicating they do not contribute to improving the model's predictions.\n"
      ],
      "metadata": {
        "id": "dhK8ZFOK7PSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bagging Classifier"
      ],
      "metadata": {
        "id": "iPrIn-sb7geJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default bagging classifier and fit\n",
        "bagging = BaggingClassifier(random_state=1)\n",
        "training_time_bagging = timeit.timeit(lambda:train_model(bagging,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=bagging,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_bagging)"
      ],
      "metadata": {
        "id": "QH5NFsNs7nzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Default Bagging seems to overfit training set\n",
        "- Time taken to train the model is highest among other models\n"
      ],
      "metadata": {
        "id": "I3QcjBN17dhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Confusion Matrix on test data and training\n",
        "\n",
        "confusion_matrix_sklearn(bagging, X_train, y_train,cs_training)\n",
        "confusion_matrix_sklearn(bagging, X_test, y_test,cs_testing)"
      ],
      "metadata": {
        "id": "HhXipO5E8vDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- TP,TN,FP,FN all seems to be reduced."
      ],
      "metadata": {
        "id": "WjWjDuLW72c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "bagging_performance_default_train=model_performance_classification_sklearn(model=bagging, predictors=X_train,target=y_train)\n",
        "bagging_performance_default_test=model_performance_classification_sklearn(model=bagging, predictors=X_test, target=y_test)\n",
        "train_performance = [\n",
        "    bagging_performance_default_train.T\n",
        "]\n",
        "test_performance = [\n",
        "    bagging_performance_default_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Bagging - default\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance,test_performance,model_names)"
      ],
      "metadata": {
        "id": "etqdyGdO8U4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Bagging with default seems to overfit the training set.Thats why we see the higher Accuracy,Recall precision and F1 (99%) and it drastically reduced in test set.**(Accuracy:70% ,Recall:78%,Precision:78% and F1=78%)**\n"
      ],
      "metadata": {
        "id": "wvOfa6_p-MKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bagging Classifier with Logistic Regression"
      ],
      "metadata": {
        "id": "EwhORiec_Rwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default bagging classifier with logistic regression and fit\n",
        "bagging_log = BaggingClassifier(estimator=LogisticRegression(),random_state=1)\n",
        "training_time_bagging_log = timeit.timeit(lambda:train_model(bagging_log,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=bagging_log,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_bagging_log)"
      ],
      "metadata": {
        "id": "b-DQO2nL-0SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obsrvations:\n",
        "- Though a simpler model with LogisticRgression but it does not overfit.\n",
        "- Score is same as prepruned model\n",
        "- Training time is high(4.15).\n"
      ],
      "metadata": {
        "id": "B-mudqig8Z29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Confusion Matrix on test data and training\n",
        "\n",
        "confusion_matrix_sklearn(bagging_log, X_train, y_train,cs_training)\n",
        "confusion_matrix_sklearn(bagging_log, X_test, y_test,cs_testing)"
      ],
      "metadata": {
        "id": "Z7Z8WJa386pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- This model can predict more certified case **(TP)**\n",
        "- This model has more **FP** compared to previous models\n",
        "- **FN** are reduced a bit\n",
        "- Same performance as the Hypertuned decssion tree"
      ],
      "metadata": {
        "id": "aZBt26et9DYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test and combine with deafult bagging model\n",
        "bagging_performance_default_train_log=model_performance_classification_sklearn(model=bagging_log, predictors=X_train,target=y_train)\n",
        "bagging_performance_default_test_log=model_performance_classification_sklearn(model=bagging_log, predictors=X_test, target=y_test)\n",
        "train_performance_log = [\n",
        "    bagging_performance_default_train.T,\n",
        "    bagging_performance_default_train_log.T\n",
        "]\n",
        "test_performance_log = [\n",
        "    bagging_performance_default_test.T,\n",
        "    bagging_performance_default_test_log.T\n",
        "]\n",
        "# Name of model\n",
        "model_names = [\n",
        "    \"Bagging - default\",\n",
        "    \"Bagging - Logistic\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_log,test_performance_log,model_names)"
      ],
      "metadata": {
        "id": "3Q9osTYQ_ppG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Though logistic regression is simple model unlike decision tree it performs well with test data .\n",
        "- We have observed that the perfomance of this is very near to our decession tree pre(Grid Search CV) and post prunning model which is quite impressive as **F1** score is near to **81%**, **Precision** is at **72%** and even **Recall** is at **91%**"
      ],
      "metadata": {
        "id": "zNZIYMqUAZPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Classifier\n"
      ],
      "metadata": {
        "id": "6UBN9zfOBbQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the random forest classifier\n",
        "rf_estimator=RandomForestClassifier(random_state=1)\n",
        "training_time_rf = timeit.timeit(lambda:train_model(rf_estimator,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=rf_estimator,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_rf)"
      ],
      "metadata": {
        "id": "FRWoyoUgBneD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- We overfit the training set\n",
        "-  Though not slowest but still slower"
      ],
      "metadata": {
        "id": "nHuZ7DWs993F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Confusion Matrix on test data\n",
        "confusion_matrix_sklearn(rf_estimator, X_test, y_test,cs_training)\n",
        "confusion_matrix_sklearn(rf_estimator, X_test, y_test,cs_testing)"
      ],
      "metadata": {
        "id": "eFhwzYjSBuNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "rf_performance_default_train=model_performance_classification_sklearn(model=bagging, predictors=X_train,target=y_train)\n",
        "rf_performance_default_test=model_performance_classification_sklearn(model=bagging, predictors=X_test, target=y_test)\n",
        "train_performance_rf = [\n",
        "    rf_performance_default_train.T\n",
        "]\n",
        "test_performance_rf = [\n",
        "    rf_performance_default_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Random Forest - default\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_rf,test_performance_rf,model_names)"
      ],
      "metadata": {
        "id": "SIC3WvtXCqHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Observations:\n",
        "- Like decession tree and bagging deafult random forest seems to overfit and F1 score is still lesser then the postpruned decision tree and pre puned decision tree"
      ],
      "metadata": {
        "id": "ffcupWdGC592"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning Bagging Classifier\n",
        "**Some of the important hyperparameters available for bagging classifier are:**\n",
        "\n",
        "- base_estimator: The base estimator to fit on random subsets of the dataset. If None(default), then the base estimator is a decision tree.\n",
        "- n_estimators: The number of trees in the forest, default = 100.\n",
        "max_features: The number of features to consider when looking for the best split.\n",
        "- bootstrap: Whether bootstrap samples are used when building trees. If False, the entire dataset is used to build each tree, default=True.\n",
        "- bootstrap_features: If it is true, then features are drawn with replacement. Default value is False.\n",
        "- max_samples: If bootstrap is True, then the number of samples to draw from X to train each base estimator. If None (default), then draw N samples, where N is the number of observations in the train data.\n",
        "- oob_score: Whether to use out-of-bag samples to estimate the generalization accuracy, default=Fals\n"
      ],
      "metadata": {
        "id": "4mEI668YDfPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the type of classifier.\n",
        "bagging_estimator_tuned = BaggingClassifier(random_state=1)\n",
        "\n",
        "# Grid of parameters\n",
        "parameters = {'max_samples': [0.7,0.8,0.9,1],\n",
        "              'max_features': [0.7,0.8,0.9,1],\n",
        "              'n_estimators' : [10,20,30,40,50],\n",
        "             }\n",
        "\n",
        "\n",
        "\n",
        "# Run the grid search\n",
        "grid__bagging_obj = GridSearchCV(bagging_estimator_tuned, parameters, scoring='f1',cv=4)\n",
        "grid__bagging_obj = grid__bagging_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "bagging_estimator_tuned = grid__bagging_obj.best_estimator_\n",
        "\n"
      ],
      "metadata": {
        "id": "j7HnQmkYDRJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_estimator_tuned"
      ],
      "metadata": {
        "id": "8q4115ZT_bv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the best algorithm to the data.\n",
        "training_time_bagging_tuned = timeit.timeit(lambda:train_model(bagging_estimator_tuned,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=bagging_estimator_tuned,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_bagging_tuned)"
      ],
      "metadata": {
        "id": "d7xJnSqYEHmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- It seems to overfit the training data\n",
        "- Training time is slow"
      ],
      "metadata": {
        "id": "QEkAGfFak4QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Confusion Matrix on test data\n",
        "confusion_matrix_sklearn(bagging_estimator_tuned, X_test, y_test,cs_training)\n",
        "confusion_matrix_sklearn(bagging_estimator_tuned, X_test, y_test,cs_testing)"
      ],
      "metadata": {
        "id": "sXtvjsEv_E3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation\n",
        "- We observed increase in **TP** detection by model from random forest\n",
        "- We observed reduction in **FN**\n",
        "\n",
        "we still find this model is over fitting the data and performance is not same as Decisions Tree model."
      ],
      "metadata": {
        "id": "s7uSFNqH_VYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "grid_bag_performance_default_train=model_performance_classification_sklearn(model=bagging_estimator_tuned, predictors=X_train,target=y_train)\n",
        "grid_bag_performance_default_test=model_performance_classification_sklearn(model=bagging_estimator_tuned, predictors=X_test, target=y_test)\n",
        "train_performance_grid_bag = [\n",
        "    grid_bag_performance_default_train.T\n",
        "]\n",
        "test_performance_grid_bag = [\n",
        "    grid_bag_performance_default_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Bagging - HyperParameterTuned\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_grid_bag,test_performance_grid_bag,model_names)"
      ],
      "metadata": {
        "id": "jBvfDiHHFwMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- After hyper parameter tuning we can see there is increase in **F1** score 82% and even **Recall** is increase to 89% as well.\n",
        "- **Precision** is at 76%\n",
        "- We can see the performace almost similar to decession tree pre and post prunning one."
      ],
      "metadata": {
        "id": "3apGrgXxGk4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Classifer Hyper Parameter Tuning"
      ],
      "metadata": {
        "id": "ogg8B6VDWJIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the type of classifier.\n",
        "rf_tree_tuned = RandomForestClassifier(random_state=1, bootstrap=True)\n",
        "\n",
        "parameters = {\n",
        "    \"max_depth\": [1, 2, 3, 4,5,6],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"],\n",
        "    \"min_samples_split\": [3, 5],\n",
        "    'n_estimators' : [10,20,30,40,50],\n",
        "\n",
        "}\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj_rf = GridSearchCV(rf_tree_tuned, parameters, scoring='f1', cv=5)\n",
        "grid_obj_rf = grid_obj_rf.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "rf_tree_tuned = grid_obj_rf.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data.\n",
        "training_time_rf_tuned = timeit.timeit(lambda:train_model(rf_tree_tuned,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=rf_tree_tuned,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_rf_tuned)"
      ],
      "metadata": {
        "id": "ujAadyVVYxRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "-  we donot overfit the data\n",
        "-  Score for both train and test is at 71%\n",
        "-  Training time is not slow .It's fast"
      ],
      "metadata": {
        "id": "6wtwUO1TDmd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix on bagging estimator tuned\n",
        "confusion_matrix_sklearn(rf_tree_tuned, X_test, y_test,cs_training)\n",
        "confusion_matrix_sklearn(rf_tree_tuned, X_test, y_test,cs_testing)"
      ],
      "metadata": {
        "id": "YTPzCfQVBiU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- This model is good at predicting positive cases\n",
        "- **TP**  (65%)with random forest tuned\n",
        "- **FN** is reduced further by 4%(2.76%)\n",
        "- **FP** is increased by 5%(20%) compared to previous model so there will be some false positive"
      ],
      "metadata": {
        "id": "mKLg-GAaB4oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "rf_tuned_performance_train=model_performance_classification_sklearn(model=rf_tree_tuned, predictors=X_train,target=y_train)\n",
        "rf_tuned_performance_test=model_performance_classification_sklearn(model=rf_tree_tuned, predictors=X_test, target=y_test)\n",
        "train_performance_rf_tuned= [\n",
        "    rf_tuned_performance_train.T\n",
        "]\n",
        "test_performance_rf_tuned = [\n",
        "    rf_tuned_performance_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Random Forest - HyperParameterTuned\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_rf_tuned,test_performance_rf_tuned,model_names)"
      ],
      "metadata": {
        "id": "O8bnP-0obLI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- There is slight increase on F1 score compared to bagging tuned model (82%)\n",
        "- There is increase in recall (95%) compared to bagging tuned .\n",
        "- Pression is reduced by 5% (71%) compared to bagging tuned which means there is more false positives."
      ],
      "metadata": {
        "id": "ifWURVEkgBSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdaBoost Classifier"
      ],
      "metadata": {
        "id": "PqvLoYu5gvIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaboost Classifier training with default\n",
        "ab_classifier = AdaBoostClassifier(random_state=1)\n",
        "# Fit the best algorithm to the data.\n",
        "training_time_ab = timeit.timeit(lambda:train_model(ab_classifier,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=ab_classifier,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_ab)"
      ],
      "metadata": {
        "id": "NqjuIMq-fwL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- No overfitting\n",
        "- Training time is bit slow"
      ],
      "metadata": {
        "id": "_tCtcJtoDkNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for addaboost\n",
        "confusion_matrix_sklearn(ab_classifier,X_train,y_train,cs_training)\n",
        "confusion_matrix_sklearn(ab_classifier,X_test,y_test,cs_testing)"
      ],
      "metadata": {
        "id": "t5m9bYKuho0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "ab_performance_train=model_performance_classification_sklearn(model=ab_classifier, predictors=X_train,target=y_train)\n",
        "ab_performance_test=model_performance_classification_sklearn(model=ab_classifier, predictors=X_test, target=y_test)\n",
        "train_performance_ada_tuned= [\n",
        "    ab_performance_train.T\n",
        "]\n",
        "test_performance_ada_tuned = [\n",
        "    ab_performance_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Ada Boost\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_ada_tuned,test_performance_ada_tuned,model_names)"
      ],
      "metadata": {
        "id": "5-66hIoGh2tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation:\n",
        "-  The model performance is almost same as Tuned baggig classifier model with Accuracy score of 73% and F1 score of 82%\n"
      ],
      "metadata": {
        "id": "bLrmr90lihN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting"
      ],
      "metadata": {
        "id": "Sof7Blxij8CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradient Boosting classifoer and fit with training set\n",
        "gbcl = GradientBoostingClassifier(n_estimators = 50,random_state=1)\n",
        "# Fit the best algorithm to the data.\n",
        "training_time_gbcl = timeit.timeit(lambda:train_model(gbcl,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=ab_classifier,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_gbcl)"
      ],
      "metadata": {
        "id": "KbeTO5Jij_2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "Training time is moderate and no overfitting"
      ],
      "metadata": {
        "id": "why85iQaEvML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for gradient boost\n",
        "confusion_matrix_sklearn(gbcl,X_train,y_train,cs_training)\n",
        "confusion_matrix_sklearn(gbcl,X_test,y_test,cs_testing)"
      ],
      "metadata": {
        "id": "ewRPT-Yym_uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation:\n",
        "- There is a slight improvement with graident boosting over ada boost  in terms of **FP** .\n",
        "- Slight reduction with **TP** (57%)\n",
        "- This model caught the nagative pretty well **TN** (incraese in 3%)\n"
      ],
      "metadata": {
        "id": "K_CpZWgelKHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "gb_performance_train=model_performance_classification_sklearn(model=gbcl, predictors=X_train,target=y_train)\n",
        "gb_performance_test=model_performance_classification_sklearn(model=gbcl, predictors=X_test, target=y_test)\n",
        "train_performance_gb_tuned= [\n",
        "    gb_performance_train.T\n",
        "]\n",
        "test_performance_gb_tuned = [\n",
        "    gb_performance_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Gradinet Boost - HyperParameterTuned\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_gb_tuned,test_performance_gb_tuned,model_names)"
      ],
      "metadata": {
        "id": "-rBmh-61keWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- This model precision is better (78%)\n",
        "- F1 score is same as adaboost and other equivellent tuned model we had covered before\n"
      ],
      "metadata": {
        "id": "vh9xoEuolEUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradinet Boosting With Class Weights"
      ],
      "metadata": {
        "id": "mfOHatfcvhmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sample weights\n",
        "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "# Initialize and train Gradient Boosting with sample weights\n",
        "gb_clf_tuned = GradientBoostingClassifier(random_state=1)\n",
        "training_time_gbcl_tuned = timeit.timeit(lambda:gb_clf_tuned.fit(X_train, y_train, sample_weight=sample_weights), number=1)\n",
        "printmodelscoreandtrainTime(model=gb_clf_tuned,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_gbcl_tuned)"
      ],
      "metadata": {
        "id": "0_6fD_xrvmNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- We donot observe any overfitting with training set\n",
        "- Training time is higher with gardient boosting slowest like random forest."
      ],
      "metadata": {
        "id": "oxsM3BjYHjV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for gradient boost\n",
        "confusion_matrix_sklearn(gb_clf_tuned,X_train,y_train,cs_training)\n",
        "confusion_matrix_sklearn(gb_clf_tuned,X_test,y_test,cs_testing)"
      ],
      "metadata": {
        "id": "Pt1l_snjv7C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "This model not good at detecting positive cases as TP is reduced."
      ],
      "metadata": {
        "id": "b8KtxkCNISlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "gb_clf_tuned_performance_train=model_performance_classification_sklearn(model=gb_clf_tuned, predictors=X_train,target=y_train)\n",
        "gb_clf_tuned_performance_test=model_performance_classification_sklearn(model=gb_clf_tuned, predictors=X_test, target=y_test)\n",
        "train_performance_gb_clf_tuned= [\n",
        "    gb_clf_tuned_performance_train.T\n",
        "]\n",
        "test_performance_gb_clf_tuned_tuned = [\n",
        "    gb_clf_tuned_performance_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Gradinet Boost - HyperParameterTuned\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_gb_clf_tuned,test_performance_gb_clf_tuned_tuned,model_names)"
      ],
      "metadata": {
        "id": "xcgw5JEYwAM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation:\n",
        "Though we had increased precession here but with this F1 score reduced ."
      ],
      "metadata": {
        "id": "DlfOxWnrwn_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradinet Boosting With Grid Serach CV Hyper Tuning"
      ],
      "metadata": {
        "id": "LWolzr283H1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "# Initialize the grid search\n",
        "grid_search_gbcl = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, scoring='f1')\n",
        "grid_search_gbcl.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "3AhoYJLm3HSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show best Params\n",
        "grid_search_gbcl.best_params_"
      ],
      "metadata": {
        "id": "VfVRQgdMilwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbcl_bestmodel_tuned=grid_search_gbcl.best_estimator_\n",
        "training_time_gbcl__grid_tuned = timeit.timeit(lambda:train_model(gbcl_bestmodel_tuned,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=gbcl_bestmodel_tuned,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_gbcl__grid_tuned)"
      ],
      "metadata": {
        "id": "rYVdZ32gmet0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- The model is not overfitting.Test and training score is around 75\n",
        "- Training time is higher"
      ],
      "metadata": {
        "id": "D5E4iFHyr6Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for XG boost on trainings\n",
        "confusion_matrix_sklearn(gbcl_bestmodel_tuned,X_train,y_train,cs_training)\n",
        "confusion_matrix_sklearn(gbcl_bestmodel_tuned,X_train,y_train,cs_testing)"
      ],
      "metadata": {
        "id": "VTe1FIP6rlwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "gbcl_hyp_tuned_performance_train=model_performance_classification_sklearn(model=gbcl_bestmodel_tuned, predictors=X_train,target=y_train)\n",
        "gbcl_hyp_tuned_performance_test=model_performance_classification_sklearn(model=gbcl_bestmodel_tuned, predictors=X_test, target=y_test)\n",
        "train_performance_gcbl_hyp_tuned= [\n",
        "    gbcl_hyp_tuned_performance_train.T\n",
        "]\n",
        "test_performance_gcbl_hyp_tuned = [\n",
        "    gbcl_hyp_tuned_performance_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Gradinet Boost Hyper Tyned\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_gcbl_hyp_tuned,test_performance_gcbl_hyp_tuned,model_names)"
      ],
      "metadata": {
        "id": "euObYAgAsGLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- This model F1 score 82 so not so much improvement  over normal gradient boosting with hyper tuning\n",
        "- Precision is at 78 which is same as before with graident boosting\n",
        "-"
      ],
      "metadata": {
        "id": "frh2pndevoo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost Classifier\n"
      ],
      "metadata": {
        "id": "9ZMhknetmQb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create XG Boost and fit\n",
        "xgb = XGBClassifier(random_state=1,eval_metric='logloss')\n",
        "xgb.fit(X_train,y_train)\n",
        "training_time_xgb = timeit.timeit(lambda:train_model(xgb,Xtrain=X_train,ytrain=y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=xgb,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_xgb)"
      ],
      "metadata": {
        "id": "hkicyNGDmJq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for XG boost on trainings\n",
        "confusion_matrix_sklearn(xgb,X_train,y_train,cs_training)\n",
        "confusion_matrix_sklearn(xgb,X_train,y_train,cs_testing)"
      ],
      "metadata": {
        "id": "UdGsG-bvmm8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- This model has less FP (11.13%)\n",
        "- Good at detecting positive cases\n",
        "-  False Nagative is at 4.71%"
      ],
      "metadata": {
        "id": "idZwXxdooHQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Precession f1 score and recall for both train and test\n",
        "xgb_performance_train=model_performance_classification_sklearn(model=xgb, predictors=X_train,target=y_train)\n",
        "xgb_performance_test=model_performance_classification_sklearn(model=xgb, predictors=X_test, target=y_test)\n",
        "train_performance_xgb_tuned= [\n",
        "    xgb_performance_train.T\n",
        "]\n",
        "test_performance_xgb_tuned = [\n",
        "    xgb_performance_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"XGradinet Boost\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_xgb_tuned,test_performance_xgb_tuned,model_names)"
      ],
      "metadata": {
        "id": "Y7LLoa2rozrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- F1 score is dropped a little compared to Addaboost and gradinet boost (81%)\n",
        "- Precession is at 77% Reduced in compared to gradinet boosting.\n",
        "- Recall is at 85% is improved a bit over gradient boosting\n",
        "- Accuracy is at 73% bit reduced from gradient boosting\n",
        " So Overall not much improvement."
      ],
      "metadata": {
        "id": "coBphCFOpl29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cat Boost (We donot need Encoding)"
      ],
      "metadata": {
        "id": "q5tt7biMqlee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Identify categorical feature indices\n",
        "cat_features = X_train_cat.select_dtypes(include=['category', 'object']).columns\n",
        "cat_feature_indices = [X_train_cat.columns.get_loc(col) for col in cat_features]\n",
        "\n",
        "# Create and fit the CatBoostClassifier\n",
        "catb = CatBoostClassifier(cat_features=cat_feature_indices, random_state=1, verbose=0,task_type='GPU', iterations=1000, learning_rate=0.1, depth=6)\n",
        "training_time_cat_boost = timeit.timeit(lambda:catb.fit(X_train_cat, y_train_cat), number=1)\n",
        "printmodelscoreandtrainTime(model=catb,X_train=X_train_cat,y_train=y_train_cat,X_test=X_test_cat,y_test=y_test_cat,training_time=training_time_cat_boost)\n"
      ],
      "metadata": {
        "id": "4eNOLYymqBtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- No overfitting but the model training is slow  (may be due to handling of catogorical variables)"
      ],
      "metadata": {
        "id": "51M46AASS_sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for cat boost on trainings\n",
        "confusion_matrix_sklearn(catb,X_train_cat,y_train_cat,cs_training)\n",
        "confusion_matrix_sklearn(catb,X_test_cat,y_test_cat,cs_testing)"
      ],
      "metadata": {
        "id": "Bs4x9fXjrjG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Model has Low FP\n",
        "- TP is around 58% which is lesser then addaboost\n",
        "- FN is at 8.95%"
      ],
      "metadata": {
        "id": "RVz3N59-lt6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Print Precession f1 score and recall for both train and test\n",
        "catb_performance_train=model_performance_classification_sklearn(model=catb, predictors=X_train_cat,target=y_train_cat)\n",
        "catb_performance_test=model_performance_classification_sklearn(model=catb, predictors=X_test_cat, target=y_test_cat)\n",
        "train_performance_catb_tuned= [\n",
        "    catb_performance_train.T\n",
        "]\n",
        "test_performance_catb_tuned = [\n",
        "    catb_performance_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"Cat Boost\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_catb_tuned,test_performance_catb_tuned,model_names)"
      ],
      "metadata": {
        "id": "ndM048L6ruZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "- Performance of catboost classifiers over all good with much handling of catogorical variable .\n",
        "- **F1** score is at 82% with **Accuracy** of model is around 74%\n",
        "- **Precision** is at 78%"
      ],
      "metadata": {
        "id": "vEzfmJWcsfGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LGBMClassifier"
      ],
      "metadata": {
        "id": "Lg2y_KkRs0JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create LGBMClassifier  and test and train\n",
        "lgbm = LGBMClassifier(random_state=1)\n",
        "training_time_lgbm = timeit.timeit(lambda:train_model(lgbm,X_train,y_train), number=1)\n",
        "printmodelscoreandtrainTime(model=lgbm,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,training_time=training_time_lgbm)"
      ],
      "metadata": {
        "id": "K47BuRjgsN53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for lgbm on trainings and test\n",
        "confusion_matrix_sklearn(lgbm,X_train,y_train,cs_training)\n",
        "confusion_matrix_sklearn(lgbm,X_test,y_test,cs_testing)"
      ],
      "metadata": {
        "id": "ln3s1yv8tSdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Print Precession f1 score and recall for both train and test\n",
        "lgbm_performance_train=model_performance_classification_sklearn(model=lgbm, predictors=X_train,target=y_train)\n",
        "lgbm_performance_test=model_performance_classification_sklearn(model=lgbm, predictors=X_test, target=y_test)\n",
        "train_performance_lgbm_tuned= [\n",
        "    lgbm_performance_train.T\n",
        "]\n",
        "test_performance_lgbm_tuned = [\n",
        "    lgbm_performance_test.T\n",
        "]\n",
        "model_names = [\n",
        "    \"LGBMClassifier\",\n",
        "]\n",
        "# Create a dataframe with all combined\n",
        "compare_model_performance(train_performance_lgbm_tuned,test_performance_lgbm_tuned,model_names)"
      ],
      "metadata": {
        "id": "wnR55sSOteP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation;\n",
        "- The performance of this model similar to previous good model and exactly similar to cat boost\n",
        "- **F1** score is at 82% with Accuracy of model is around 74%\n",
        "- **Precision** is around 79%\n",
        "- **Recall** is at 86%\n"
      ],
      "metadata": {
        "id": "9mjqdVVMt38R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance_df, x='Importance', y='Feature', palette=\"Blues_d\")\n",
        "\n",
        "# Add a title and labels\n",
        "plt.title(\"Feature Importance from Decision Tree\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p0X236ETIGbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Model Selection:\n",
        "- We will choose only the best model where F1 score is above 80 and then compare them here"
      ],
      "metadata": {
        "id": "GSOPDJQVG4wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concat above df to compare\n",
        "models_test_comp_df = pd.concat(\n",
        "    [\n",
        "        dec_tree_performance__prun_default.T,# choosen the Decision Tree Post Pruning\n",
        "        dec_tree_performance__pre_prun_default.T, # choosen the Decision Tree Post Pruning with grid serach CV\n",
        "        bagging_performance_default_test_log.T, # choosen the  Bagging Classifier with Logistic Regression as estimator\n",
        "        grid_bag_performance_default_test.T,  # choosen the  Bagging Classifier hyper parameter tunes\n",
        "        rf_tuned_performance_test.T, # choosen Random Forest Hyperparam Tuned\n",
        "        ab_performance_test.T, # choosen Addaboost default\n",
        "        gb_performance_test.T,# Choosen  Gradient Boosting Default\n",
        "        gbcl_hyp_tuned_performance_test.T, # choosen  gbcl_hyp_tuned_performance_test Hyper parameter tune\n",
        "        xgb_performance_test.T,# choosen  XG Boost\n",
        "        catb_performance_test.T, # choosen  Cat Boost\n",
        "        lgbm_performance_test.T, # choosen  LGBM Classifier\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "# Give sensible Column names\n",
        "models_test_comp_df.columns = [\n",
        "    \"Decision Tree - Post Pruning\",\n",
        "    \"Decision Tree - Pre Pruning\",\n",
        "    \"Bagging - Logistic Regression\",\n",
        "    \"Bagging - HyperParameterTuned\",\n",
        "    \"Random Forest - HyperParameterTuned\",\n",
        "    \"Ada Boost\",\n",
        "    \"Gradinet Boost\",\n",
        "    \"Gradinet Boost - HyperParameterTuned\",\n",
        "    \"XGradinet Boost\",\n",
        "    \"Cat Boost\",\n",
        "    \"LGBMClassifier\",\n",
        "]\n",
        "models_test_comp_df"
      ],
      "metadata": {
        "id": "cpJRtZOOCteO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights and Recommendation:\n",
        "\n",
        "- Education level\n",
        "  - Candidate applying for Visa  with high school  will more than likely be denied. where as, applications jobs requiring a Master's degree or doctorate are very likely to be approved for visa.\n",
        "  - Masters has Highest mean prevailing wage around **78843** followed by bachelor **73405**\n",
        "  - Doctorate has lowest mean prevailing wage 64561\n",
        "\n",
        "- Prior job experience\n",
        "  - Candidate applying for a Visa  without any previous job experience required for Job is more likley to be denied than an applicant for a job with experience.\n",
        "- Prevailing wage\n",
        "  - Applicants who are certified or got their visa approved have higher mean prevailing wage\n",
        "- Continent\n",
        " - it has been observed that applicants from Europe, Africa, and Asia have higher chances of visa certification.\n",
        " - Asia has highest mean prevaling wage 79543 approx where as south America is lowest (60209).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "16Nr4tu30jql"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}